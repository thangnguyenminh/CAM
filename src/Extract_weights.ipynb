{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.12"},"colab":{"name":"Extract_weights.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"QYkULRzvXS29","colab_type":"text"},"source":["# Find the variable names and values that are saved in a checkpoint"]},{"cell_type":"code","metadata":{"id":"BvFKg70vXgXd","colab_type":"code","outputId":"d9218f81-fabd-46d2-ce65-a51c2a14858b","executionInfo":{"status":"ok","timestamp":1564564536820,"user_tz":-420,"elapsed":1015,"user":{"displayName":"Thắng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/-R1dTC5_z8yQ/AAAAAAAAAAI/AAAAAAAAAFY/DBZz-Bt-Qqg/s64/photo.jpg","userId":"15805147027279298839"}},"colab":{"base_uri":"https://localhost:8080/","height":59}},"source":["from google.colab import drive\n","import os\n","import sys\n","\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/My Drive/CAM/src')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IfYLJZXwXS2_","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.python import pywrap_tensorflow\n","import pickle\n","import numpy as np\n","# source: https://stackoverflow.com/a/41917296/9815299"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z93mfbCUXS3F","colab_type":"code","outputId":"4766bf98-1278-4fca-ab2a-06c2a66adad0","executionInfo":{"status":"ok","timestamp":1564564597976,"user_tz":-420,"elapsed":9162,"user":{"displayName":"Thắng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/-R1dTC5_z8yQ/AAAAAAAAAAI/AAAAAAAAAFY/DBZz-Bt-Qqg/s64/photo.jpg","userId":"15805147027279298839"}},"colab":{"base_uri":"https://localhost:8080/","height":612}},"source":["#checkpoint_path = os.path.join(model_dir, \"model.ckpt\")\n","checkpoint_path = \"/content/drive/My Drive/CAM/models/na4GradCAM/model-24\"\n","reader = pywrap_tensorflow.NewCheckpointReader(checkpoint_path)\n","var_to_shape_map = reader.get_variable_to_shape_map()\n","\n","# If extract_weight for CAM processing: CAM = True\n","# Else, in case of Grad-CAM: CAM = False\n","CAM = False\n","new_weights = {}\n","for key in var_to_shape_map:\n","#     print(\"tensor_name: \", key)\n","#     print(reader.get_tensor(key)) # Remove this is you want to print only variable name\n","    \n","    layer_name, remainder = key.split('/')\n","    print('name', layer_name, 'remainder', remainder)\n","    if layer_name not in new_weights:\n","        if 'b' in remainder:\n","            new_weights[layer_name] = [0]\n","            # append the new number to the existing array at this slot\n","            new_weights[layer_name].append(reader.get_tensor(key))\n","        else:\n","            # create a new array in this slot\n","            if CAM:\n","              new_weights[layer_name] = [np.transpose(reader.get_tensor(key))]\n","            else:\n","              new_weights[layer_name] = [reader.get_tensor(key)]\n","\n","    else:\n","        if 'b' in remainder:\n","            # append the new number to the existing array at this slot\n","            new_weights[layer_name].append(reader.get_tensor(key))\n","        else:\n","            # create a new array in this slot\n","            if CAM:\n","              new_weights[layer_name][0] = np.transpose(reader.get_tensor(key))\n","            else:\n","              new_weights[layer_name][0] = reader.get_tensor(key)\n","#new_weights"],"execution_count":3,"outputs":[{"output_type":"stream","text":["('name', 'conv3_2', 'remainder', 'b')\n","('name', 'conv3_3', 'remainder', 'b')\n","('name', 'conv2_1', 'remainder', 'W')\n","('name', 'fc8', 'remainder', 'b')\n","('name', 'GAP', 'remainder', 'W')\n","('name', 'conv6', 'remainder', 'b')\n","('name', 'conv4_3', 'remainder', 'W')\n","('name', 'conv3_1', 'remainder', 'b')\n","('name', 'conv3_1', 'remainder', 'W')\n","('name', 'conv6', 'remainder', 'W')\n","('name', 'conv4_3', 'remainder', 'b')\n","('name', 'conv3_2', 'remainder', 'W')\n","('name', 'fc8', 'remainder', 'W')\n","('name', 'conv3_3', 'remainder', 'W')\n","('name', 'conv2_1', 'remainder', 'b')\n","('name', 'conv2_2', 'remainder', 'W')\n","('name', 'conv5_2', 'remainder', 'b')\n","('name', 'fc6', 'remainder', 'b')\n","('name', 'conv1_1', 'remainder', 'W')\n","('name', 'conv5_1', 'remainder', 'W')\n","('name', 'fc7', 'remainder', 'b')\n","('name', 'conv5_3', 'remainder', 'b')\n","('name', 'conv4_2', 'remainder', 'b')\n","('name', 'conv4_1', 'remainder', 'b')\n","('name', 'conv1_2', 'remainder', 'b')\n","('name', 'conv4_2', 'remainder', 'W')\n","('name', 'conv4_1', 'remainder', 'W')\n","('name', 'conv1_2', 'remainder', 'W')\n","('name', 'conv2_2', 'remainder', 'b')\n","('name', 'fc6', 'remainder', 'W')\n","('name', 'conv5_2', 'remainder', 'W')\n","('name', 'conv5_1', 'remainder', 'b')\n","('name', 'conv5_3', 'remainder', 'W')\n","('name', 'fc7', 'remainder', 'W')\n","('name', 'conv1_1', 'remainder', 'b')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fajuZ87gXS3L","colab_type":"code","colab":{}},"source":["# Save: dict 2 pickle\n","#https://stackoverflow.com/a/11218504/9815299\n","with open('../data/new_na_GradCAM.pickle', 'wb') as handle:\n","    pickle.dump(new_weights, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIXIX_Xy2sH0","colab_type":"code","colab":{}},"source":["# Save: dict to npy\n","np.save(\"/content/drive/My Drive/CAM/data/new_na_GradCAM.npy\", new_weights)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l5QhqNJbe_l4","colab_type":"code","outputId":"ea582ae4-4109-4871-eb7c-f5c665cafee7","executionInfo":{"status":"ok","timestamp":1564559481604,"user_tz":-420,"elapsed":13325,"user":{"displayName":"Thắng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/-R1dTC5_z8yQ/AAAAAAAAAAI/AAAAAAAAAFY/DBZz-Bt-Qqg/s64/photo.jpg","userId":"15805147027279298839"}},"colab":{"base_uri":"https://localhost:8080/","height":293}},"source":["!pip install numpy==1.16.1"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting numpy==1.16.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/b5/63b79fe426433fa1cd110eb04a94ec0c6967e56e5f57c98caf455a5fb6e2/numpy-1.16.1-cp27-cp27mu-manylinux1_x86_64.whl (17.0MB)\n","\u001b[K     |████████████████████████████████| 17.0MB 1.9MB/s \n","\u001b[31mERROR: fastai 0.7.0 has requirement torch<0.4, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Found existing installation: numpy 1.16.4\n","    Uninstalling numpy-1.16.4:\n","      Successfully uninstalled numpy-1.16.4\n","Successfully installed numpy-1.16.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"sf2ekPz1XS3O","colab_type":"code","outputId":"d9d657e6-b4da-4ab1-dd6f-0b08ebcd629b","executionInfo":{"status":"ok","timestamp":1564559487932,"user_tz":-420,"elapsed":5075,"user":{"displayName":"Thắng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/-R1dTC5_z8yQ/AAAAAAAAAAI/AAAAAAAAAFY/DBZz-Bt-Qqg/s64/photo.jpg","userId":"15805147027279298839"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# compare new weight to vgg_weight\n","with open('../data/new_na_CAM.pickle', 'r') as f:\n","    x = pickle.load(f)\n","# with open('../data/caffe_layers_value.pickle', 'r') as f:\n","#     y = pickle.load(f)\n","y = np.load(\"/content/drive/My Drive/Grad-CAM-tensorflow/model/vgg16.npy\", encoding=\"latin1\", allow_pickle=True).item()\n","\n","# compare 2 dicts\n","def compare(first, second):\n","    sharedKeys = set(first.keys()).intersection(second.keys())\n","    print(sharedKeys)\n","    for key in sharedKeys:\n","        print'layer:',key\n","        if first[key][0].shape != second[key][0].shape:\n","            print 'Key:', key, 'W1:',first[key][0].shape,' W2:',second[key][0].shape\n","            print 'W1_transpose:', first[key][0].shape\n","        else:\n","            print 'W1:',first[key][0].shape, 'W2:',second[key][0].shape\n","            \n","        if  first[key][1].shape != second[key][1].shape:\n","            print 'Key:', key, 'b1:',first[key][1].shape,' b2:',second[key][1].shape\n","            print 'b1_transpose', first[key][1].shape\n","        else:\n","            print 'b1:',first[key][0].shape, 'b2',second[key][0].shape\n","compare(x,y)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["set(['conv5_1', 'fc6', 'conv5_3', 'conv5_2', 'fc8', 'fc7', 'conv4_1', 'conv4_2', 'conv4_3', 'conv3_3', 'conv3_2', 'conv3_1', 'conv1_1', 'conv1_2', 'conv2_2', 'conv2_1'])\n","layer: conv5_1\n","Key: conv5_1 W1: (512, 512, 3, 3)  W2: (3, 3, 512, 512)\n","W1_transpose: (512, 512, 3, 3)\n","b1: (512, 512, 3, 3) b2 (3, 3, 512, 512)\n","layer: fc6\n","Key: fc6 W1: (4096, 25088)  W2: (25088, 4096)\n","W1_transpose: (4096, 25088)\n","b1: (4096, 25088) b2 (25088, 4096)\n","layer: conv5_3\n","Key: conv5_3 W1: (512, 512, 3, 3)  W2: (3, 3, 512, 512)\n","W1_transpose: (512, 512, 3, 3)\n","b1: (512, 512, 3, 3) b2 (3, 3, 512, 512)\n","layer: conv5_2\n","Key: conv5_2 W1: (512, 512, 3, 3)  W2: (3, 3, 512, 512)\n","W1_transpose: (512, 512, 3, 3)\n","b1: (512, 512, 3, 3) b2 (3, 3, 512, 512)\n","layer: fc8\n","Key: fc8 W1: (1000, 4096)  W2: (4096, 1000)\n","W1_transpose: (1000, 4096)\n","b1: (1000, 4096) b2 (4096, 1000)\n","layer: fc7\n","W1: (4096, 4096) W2: (4096, 4096)\n","b1: (4096, 4096) b2 (4096, 4096)\n","layer: conv4_1\n","Key: conv4_1 W1: (512, 256, 3, 3)  W2: (3, 3, 256, 512)\n","W1_transpose: (512, 256, 3, 3)\n","b1: (512, 256, 3, 3) b2 (3, 3, 256, 512)\n","layer: conv4_2\n","Key: conv4_2 W1: (512, 512, 3, 3)  W2: (3, 3, 512, 512)\n","W1_transpose: (512, 512, 3, 3)\n","b1: (512, 512, 3, 3) b2 (3, 3, 512, 512)\n","layer: conv4_3\n","Key: conv4_3 W1: (512, 512, 3, 3)  W2: (3, 3, 512, 512)\n","W1_transpose: (512, 512, 3, 3)\n","b1: (512, 512, 3, 3) b2 (3, 3, 512, 512)\n","layer: conv3_3\n","Key: conv3_3 W1: (256, 256, 3, 3)  W2: (3, 3, 256, 256)\n","W1_transpose: (256, 256, 3, 3)\n","b1: (256, 256, 3, 3) b2 (3, 3, 256, 256)\n","layer: conv3_2\n","Key: conv3_2 W1: (256, 256, 3, 3)  W2: (3, 3, 256, 256)\n","W1_transpose: (256, 256, 3, 3)\n","b1: (256, 256, 3, 3) b2 (3, 3, 256, 256)\n","layer: conv3_1\n","Key: conv3_1 W1: (256, 128, 3, 3)  W2: (3, 3, 128, 256)\n","W1_transpose: (256, 128, 3, 3)\n","b1: (256, 128, 3, 3) b2 (3, 3, 128, 256)\n","layer: conv1_1\n","Key: conv1_1 W1: (64, 3, 3, 3)  W2: (3, 3, 3, 64)\n","W1_transpose: (64, 3, 3, 3)\n","b1: (64, 3, 3, 3) b2 (3, 3, 3, 64)\n","layer: conv1_2\n","Key: conv1_2 W1: (64, 64, 3, 3)  W2: (3, 3, 64, 64)\n","W1_transpose: (64, 64, 3, 3)\n","b1: (64, 64, 3, 3) b2 (3, 3, 64, 64)\n","layer: conv2_2\n","Key: conv2_2 W1: (128, 128, 3, 3)  W2: (3, 3, 128, 128)\n","W1_transpose: (128, 128, 3, 3)\n","b1: (128, 128, 3, 3) b2 (3, 3, 128, 128)\n","layer: conv2_1\n","Key: conv2_1 W1: (128, 64, 3, 3)  W2: (3, 3, 64, 128)\n","W1_transpose: (128, 64, 3, 3)\n","b1: (128, 64, 3, 3) b2 (3, 3, 64, 128)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zzln6u0pBRVP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6606b9af-fa61-47cd-bb32-c42a44ea3dbe","executionInfo":{"status":"ok","timestamp":1564559633079,"user_tz":-420,"elapsed":1214,"user":{"displayName":"Thắng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/-R1dTC5_z8yQ/AAAAAAAAAAI/AAAAAAAAAFY/DBZz-Bt-Qqg/s64/photo.jpg","userId":"15805147027279298839"}}},"source":["np.shape(x['conv6'][0])"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1024, 512, 3, 3)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"uj8AG4SBgG0K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":520},"outputId":"8260ec20-5736-4aef-83af-dda0c7dd280f","executionInfo":{"status":"error","timestamp":1564481468611,"user_tz":-420,"elapsed":11456,"user":{"displayName":"Thắng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/-R1dTC5_z8yQ/AAAAAAAAAAI/AAAAAAAAAFY/DBZz-Bt-Qqg/s64/photo.jpg","userId":"15805147027279298839"}}},"source":["def npy2pickle():\n","  y = np.load(\"/content/drive/My Drive/Grad-CAM-tensorflow/model/vgg16.npy\", encoding=\"latin1\",allow_pickle=False).item()\n","\n","  with open(\"/content/drive/My Drive/Grad-CAM-tensorflow/model/vgg16.pickle\",'wb') as f: pickle.dump(y, f)\n","\n","  with open(\"/content/drive/My Drive/Grad-CAM-tensorflow/model/vgg16.pickle\",'rb') as f: y_new = pickle.load(f)"],"execution_count":5,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-5-61d69bf35365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Grad-CAM-tensorflow/model/vgg16.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Grad-CAM-tensorflow/model/vgg16.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Grad-CAM-tensorflow/model/vgg16.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 447\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[1;32m    697\u001b[0m                              \"allow_pickle=False\")\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"]}]},{"cell_type":"code","metadata":{"id":"5zsvcUToQtu2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"bf095c05-b50f-4a78-b3fa-c6d421c62a2e","executionInfo":{"status":"ok","timestamp":1564546937948,"user_tz":-420,"elapsed":864,"user":{"displayName":"Thắng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/-R1dTC5_z8yQ/AAAAAAAAAAI/AAAAAAAAAFY/DBZz-Bt-Qqg/s64/photo.jpg","userId":"15805147027279298839"}}},"source":["y.keys()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['conv5_1',\n"," 'fc6',\n"," 'conv5_3',\n"," 'fc7',\n"," 'fc8',\n"," 'conv5_2',\n"," 'conv4_1',\n"," 'conv4_2',\n"," 'conv4_3',\n"," 'conv3_3',\n"," 'conv3_2',\n"," 'conv3_1',\n"," 'conv1_1',\n"," 'conv1_2',\n"," 'conv2_2',\n"," 'conv2_1']"]},"metadata":{"tags":[]},"execution_count":13}]}]}